{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec962a6-6d5c-4a53-acba-6c05ffcce5a0",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f5700-29dc-4ee5-a12f-7a82e4522ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import PyPDF2\n",
    "import re\n",
    "import openai\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import json, requests\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "from nrclex import NRCLex\n",
    "from textstat import flesch_kincaid_grade\n",
    "from geopy.geocoders import Nominatim\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "import gradio as gr\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import xml.etree.ElementTree as ET\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6f3b1-cd89-423f-8b2a-ab62416dbfe2",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c01237-7132-46fc-9d4d-584dc3eb4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPEN_API_KEY']\n",
    "GOOGLE_API_KEY=os.environ['GOOGLE_API_KEY']\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "hf_api_key =  os.environ['HF_API_KEY']\n",
    "HF_SUMMARY_ENDPOINT = \"https://api-inference.huggingface.co/models/sshleifer/distilbart-cnn-12-6\"\n",
    "HF_NER_ENDPOINT = \"https://api-inference.huggingface.co/models/flair/ner-english-ontonotes-large\"\n",
    "HF_SENTIMENT_ENDPOINT = \"https://api-inference.huggingface.co/models/finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "HF_EMOTION_ENDPOINT = \"https://api-inference.huggingface.co/models/j-hartmann/emotion-english-distilroberta-base\"\n",
    "HF_TONE_ENDPOINT = \"https://api-inference.huggingface.co/models/yiyanghkust/finbert-tone\"\n",
    "HF_ENGMAT_ENDPOINT = \"https://api-inference.huggingface.co/models/j-hartmann/ambiguity-distilroberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c81133-054b-451e-a250-4c862bbe4c6c",
   "metadata": {},
   "source": [
    "# Text Extraction From various Files (eg:pdf,xml,..ect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d301fd-0461-4dc0-bf36-c37eb239cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility function for text extraction\"\"\"\n",
    "\n",
    "def pdf_2_txt(pdf_path):\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text_content = ' '\n",
    "        for page_number in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_number]\n",
    "            text_content += page.extract_text()\n",
    "        pdf_file.close()\n",
    "        text_content = re.sub(r'\\s+',' ',text_content)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "    return text_content\n",
    "\n",
    "\n",
    "def xml_2_text(xml_file_path):\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "    \n",
    "        # Function to recursively extract text from XML elements\n",
    "        def extract_text(element):\n",
    "            text = element.text if element.text else \"\"\n",
    "            for child in element:\n",
    "                text += extract_text(child)\n",
    "                if child.tail:\n",
    "                    text += child.tail\n",
    "            return text\n",
    "    \n",
    "        # Extract text from the root element\n",
    "        text = extract_text(root)\n",
    "        text = re.sub(r'\\s+',' ',text)\n",
    "        return  text\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903fa77-72df-4455-948f-b994b2acf9a6",
   "metadata": {},
   "source": [
    "# Patient Analysis using openAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72b6738-e923-4d27-889b-78338c0b4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OPENAI\"\"\"\n",
    "\n",
    "def openai_summary(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": patient_report + \"\\n\\n Summarize the above patient report\"}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        summary = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(20)\n",
    "        return openai_summary(patient_report)\n",
    "    return summary\n",
    "\n",
    "def openai_sentiment(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": \"provide the sentiment of  below patient report in any of the below options: Positive,Negative,Neutral\\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        sentiment = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(20)\n",
    "        return openai_sentiment(patient_report)\n",
    "    words = ['Positive','Negative','Neutral']\n",
    "    for word in words:\n",
    "        if word in sentiment:\n",
    "            res_sentiment = word\n",
    "            break\n",
    "        else:\n",
    "            res_sentiment = \"No sentiment\"\n",
    "    return res_sentiment\n",
    "\n",
    "def openai_ner(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": \"provide the Named Entities such as hospital names, patient names, doctor names,locations,medication names, and dates mentioned in the patient report\\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        entities = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(20)\n",
    "        return openai_ner(patient_report)\n",
    "    return entities\n",
    "\n",
    "def openai_emotion(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": \"Predict the emotion based on patient report from provided options : [ 'Happiness', 'Sadness', 'Anger', 'Fear', 'Suprise', 'Disgust']\\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        emotion = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(60)\n",
    "        return openai_emotion(patient_report)\n",
    "    words = [ 'Happiness', 'Sadness', 'Anger', 'Fear', 'Suprise', 'Disgust']\n",
    "    for word in words:\n",
    "        if word in emotion:\n",
    "            res_emotion = word\n",
    "            break\n",
    "        else:\n",
    "            res_emotion = \"No emotion\"\n",
    "    return res_emotion\n",
    "\n",
    "def openai_tone(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": \"Predict the Tone based on patient report from provided options : ['FORMAL', 'INFORMAL', 'OPTIMISTIC', 'HARSH']\\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        tone = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(60)\n",
    "        return openai_tone(patient_report)\n",
    "    words = ['FORMAL', 'INFORMAL', 'OPTIMISTIC', 'HARSH']\n",
    "    for word in words:\n",
    "        if word in tone:\n",
    "            res_tone = word\n",
    "            break\n",
    "        else:\n",
    "            res_tone = \"No Tone\"\n",
    "    return res_tone\n",
    "\n",
    "def openai_englishmaturity(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        prompt = [{\"role\": \"user\", \"content\": \"Predict the English Maturity of the  patient report from provided options : ['AVERAGE', 'MEDIUM', 'PROFICIENT', 'LOW']\\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        Engmat = completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(60)\n",
    "        return openai_englishmaturity(patient_report)\n",
    "    words = ['AVERAGE', 'MEDIUM', 'PROFICIENT', 'LOW']\n",
    "    for word in words:\n",
    "        if word in Engmat:\n",
    "            res_engmat = word\n",
    "            break\n",
    "        else:\n",
    "            res_engmat = \"NA\"\n",
    "    return res_engmat\n",
    "\n",
    "\n",
    "def openai_timeline(patient_report):\n",
    "    try:\n",
    "        openai.api_key = openai_api_key\n",
    "        \n",
    "        prompt = [{\"role\": \"user\", \"content\": \"List the Important Events with Time,Event Type,Event Description Group By Event type based on the below patient report  \\n\\n\" + patient_report}]\n",
    "        \n",
    "        # prompt = [{\"role\": \"user\", \"content\": \"List the Patient Events  in json format to save it to csv from json with one column as Event and another column with Date based on the below patient report  \\n\\n\" + patient_report}]\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "            messages=prompt,\n",
    "            temperature=0)\n",
    "        data = completion.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error:\",e)\n",
    "        time.sleep(60)\n",
    "        return openai_timeline(patient_report)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e46f9-a7d9-4104-8b17-5cb23a58bcb8",
   "metadata": {},
   "source": [
    "# Patient Analysis using gemini pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b6ce86-52d5-498c-abce-1727340dd407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gemini\"\"\"\n",
    "\n",
    "def gemini_summary(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"summarize the below patient report \\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_sentiment(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"provide the sentiment of  below patient report in any of the below options: Positive,Negative,Neutral\\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_NER(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"provide the Named Entities such as hospital names, patient names, doctor names,locations,medication names, and dates mentioned in the patient report as key value pairs\\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_emotion(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Predict the emotion based on patient report from provided options : [ 'Happiness', 'Sadness', 'Anger', 'Fear', 'Suprise', 'Disgust']\\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_tone(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Predict the Tone based on patient report from provided options : [ 'FORMAL', 'INFORMAL', 'OPTIMISTIC', 'HARSH']\\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_englishmaturity(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Predict the English Maturity of the  patient report from provided options : [ 'AVERAGE', 'MEDIUM', 'PROFICIENT', 'LOW']\\n\\n\" + patient_report\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_determine_sentiment_highlights(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Given a patient Report \\n\\n\" + patient_report +\"\\n\\n Provide the key words or phrases that strongly contribute to determining the sentiment of the patient report\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_determine_tone_highlights(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Given a patient Report \\n\\n\" + patient_report +\"\\n\\n Provide the key words or phrases that strongly contribute to determining the tone of the patient report\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_determine_emotion_highlights(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Given a patient Report \\n\\n\" + patient_report +\"\\n\\n Provide the key words or phrases that strongly contribute to determining the emotion of the patient report\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def gemini_determine_englishmaturity_highlights(patient_report):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    prompt = \"Given a patient Report \\n\\n\" + patient_report +\"\\n\\n Provide the key words or phrases that strongly contribute to determining the English Maturity of the patient report\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab78b46-ce6b-4117-9670-45b98984ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GDrive Files\"\"\"\n",
    "def get_files_from_gdrive():\n",
    "    # Set the path to your credentials file\n",
    "    credentials_file = r\"C:\\Users\\rakeshvmadmin\\Desktop\\Summarization\\Specific Encounter Examples\\client_secret.json\"\n",
    "    \n",
    "    # Define the scope for accessing Google Drive\n",
    "    scopes = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "    \n",
    "    # Set the path to the token file\n",
    "    token_file = './token.json'\n",
    "    \n",
    "    # Check if token file exists, otherwise authenticate the user\n",
    "    if os.path.exists(token_file):\n",
    "        credentials = Credentials.from_authorized_user_file(token_file, scopes)\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(credentials_file, scopes)\n",
    "        credentials = flow.run_local_server(port=0)\n",
    "    \n",
    "    # Save the credentials for future use\n",
    "    with open(token_file, 'w') as token:\n",
    "        token.write(credentials.to_json())\n",
    "    \n",
    "    # Build the Google Drive API service\n",
    "    drive_service = build('drive', 'v3', credentials=credentials)\n",
    "    \n",
    "    # Specify the folder ID of the Google Drive folder you want to list\n",
    "    folder_id = '11Y03gG0RGT2ulqL4X_CNf2BQNy4eVhmj'\n",
    "    \n",
    "    # Call the Drive API to list files in the folder\n",
    "    results = drive_service.files().list(q=f\"'{folder_id}' in parents\", fields=\"files(name)\").execute()\n",
    "    files = results.get('files', [])\n",
    "    \n",
    "    # Print the names of the files in the folder\n",
    "    if not files:\n",
    "        print('No files found.')\n",
    "    else:\n",
    "        Files = []\n",
    "        print('Files:')\n",
    "        for file in files:\n",
    "            Files.append(file['name'])\n",
    "    return Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86da1f8c-805f-4179-82da-40eb8ef63449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n",
      "Closing server running on port: 7861\n",
      "Closing server running on port: 7861\n",
      "Closing server running on port: 7861\n",
      "Files:\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Rate limit reached for gpt-3.5-turbo in organization org-OodEu4Y24o1DToD4VZIdNX7S on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n"
     ]
    }
   ],
   "source": [
    "def gradio_main(patient_name,Model,len,history):\n",
    "    current_directory = os.getcwd()\n",
    "    folder_name = \"Data\"\n",
    "    # path = r\"C:\\Users\\rakeshvmadmin\\Desktop\\Summarization\\Specific Encounter Examples\\Amy_Cripto_EncounterDetails.pdf\"\n",
    "    path = os.path.join(current_directory, folder_name, patient_name)\n",
    "    if patient_name.endswith(\".pdf\"):\n",
    "        patient_report = pdf_2_txt(path)\n",
    "    if patient_name.endswith(\".xml\"):\n",
    "        patient_report = xml_2_text(path)\n",
    "    summary_text,sentiment,emotion,tone,engmat,timeline=None,None,None,None,None,None\n",
    "    if Model == \"openAI\":\n",
    "        summary_text = openai_summary(patient_report)\n",
    "        sentiment = openai_sentiment(patient_report)\n",
    "        emotion = openai_emotion(patient_report)\n",
    "        tone = openai_tone(patient_report)\n",
    "        engmat = openai_englishmaturity(patient_report)\n",
    "        timeline = openai_timeline(patient_report)\n",
    "    else:\n",
    "        summary_text = gemini_summary(patient_report)\n",
    "        sentiment = gemini_sentiment(patient_report)\n",
    "        emotion = gemini_emotion(patient_report)\n",
    "        tone = gemini_tone(patient_report)\n",
    "        engmat = gemini_englishmaturity(patient_report)\n",
    "        timeline = openai_timeline(patient_report)\n",
    "    return summary_text,sentiment,emotion,tone,engmat,timeline\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=gradio_main,\n",
    "                inputs=[    gr.components.Dropdown(label=\"Select Patient Report\", choices=get_files_from_gdrive()),\n",
    "                            gr.components.Dropdown(label=\"Select Model\", choices=[\"openAI\",\"Gemini Pro\"]),\n",
    "                            gr.Slider(100, 500, step=100, value=100, label=\"Summarize Length\", info=\"Summarize between 100-500 words\"),\n",
    "                            gr.Checkbox(label=\"Yes\", info=\"Include previous history and trends ?\")\n",
    "                           ],\n",
    "                    outputs=[gr.Textbox(label=\"Patient Report Summary\", lines=10,max_lines=7),\n",
    "                             gr.Textbox(label=\"sentiment\", lines=2,max_lines=7),\n",
    "                             gr.Textbox(label=\"Emotion\", lines=2,max_lines=7),\n",
    "                             gr.Textbox(label=\"Tone\", lines=2,max_lines=7),\n",
    "                             gr.Textbox(label=\"English Maturity\", lines=2,max_lines=7),\n",
    "                             gr.Textbox(label=\"Patient_TIMELINE\", lines=10,max_lines=7),\n",
    "                            ],\n",
    "                    title=\"CharmHealth CodeRx Hackathon\",\n",
    "                    description=\"THEME : `Clinical Summary Challenge`\"\n",
    "                   )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c088a-ecbd-4d27-9c5b-a3a7b2278f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
